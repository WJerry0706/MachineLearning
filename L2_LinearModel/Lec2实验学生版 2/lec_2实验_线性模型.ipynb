{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <机器学习>课程 Lecture 2实验\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型\n",
    "\n",
    "给定一组数据,其输入数据维度为1,输出数据维度为1.\n",
    "请分别通过最小二乘法,梯度下降法和模拟退火法来拟合."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先定义基类模型.\n",
    "\n",
    "如果不带有偏置项,即为$y = w^T x$, 如果带有偏置项为$y = w^Tx + b$.\n",
    "\n",
    "计算损失使用MSE损失,即$l = \\frac{1}{2N} \\sum_{i} (\\hat y_i - y_i)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegressor():\n",
    "    \"\"\"\n",
    "    线性回归模型\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        c_in: int, c_out:int,\n",
    "        init_mean: float, init_var: float,\n",
    "        bias: bool = True\n",
    "    ) -> None:\n",
    "        '''\n",
    "        c_in: 输入数据维度\n",
    "        c_out: 输出数据维度\n",
    "        init_mean: 初始化均值\n",
    "        init_var: 初始化方差\n",
    "        bias: 是否带有偏置项\n",
    "        '''\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.bias = bias\n",
    "\n",
    "        if self.bias:\n",
    "            weight_size = (c_in+1, c_out)\n",
    "        else:\n",
    "            weight_size = (c_in, c_out)\n",
    "\n",
    "        # 初始化参数\n",
    "        self.weight = np.random.normal(\n",
    "            init_mean, init_var,\n",
    "            size=weight_size)\n",
    "\n",
    "    def predict(self, \n",
    "        x: np.ndarray,\n",
    "        weight: np.ndarray=None\n",
    "    )->np.ndarray:\n",
    "        b = x.shape[0]\n",
    "        if self.bias and x.shape[1] == self.c_in:\n",
    "            x = np.concatenate([x, np.ones((b, 1))], axis=1)\n",
    "\n",
    "        if weight is None:\n",
    "            return np.matmul(x, self.weight)\n",
    "        else:\n",
    "            return np.matmul(x, weight)\n",
    "\n",
    "    def mse_loss(self, \n",
    "        x:np.ndarray, \n",
    "        y:np.ndarray,\n",
    "        weight: np.ndarray=None\n",
    "    )-> np.ndarray:\n",
    "        b = x.shape[0]\n",
    "        if self.bias and x.shape[1] == self.c_in:\n",
    "            x = np.concatenate([x, np.ones((b, 1))], axis=1)\n",
    "\n",
    "        y_hat = self.predict(x, weight)\n",
    "        loss_val = np.sum((y_hat - y) ** 2) / (2 * b)\n",
    "\n",
    "        return loss_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文件中读取数据用于后续实验."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_filename = \"linear_data_0302_1217.npy\"\n",
    "linear_data = np.load(data_filename)\n",
    "x_data, y_data = linear_data[0, :, np.newaxis], linear_data[1, :, np.newaxis]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data,\n",
    "    train_size=0.8, shuffle=True\n",
    ")\n",
    "\n",
    "# x_data in [b, c_in]\n",
    "c_in = x_data.shape[1]\n",
    "# y_data in [b, c_out]\n",
    "c_out = y_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最小二乘法\n",
    "\n",
    "请补充代码,完成最小二乘法拟合的线性回归模型.\n",
    "\n",
    "权重计算为$w = (x^Tx)^{-1}x^Ty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LeastSquareRegressor(LinearRegressor):\n",
    "    \"\"\"\n",
    "    使用最小二乘法拟合线性模型\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        c_in: int, c_out: int,\n",
    "        init_mean: float, init_var: float,\n",
    "        bias: bool = True\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__(c_in, c_out, init_mean, init_var, bias)\n",
    "\n",
    "    def fit_least_square(self,\n",
    "        x: np.ndarray, y: np.ndarray\n",
    "    )-> None:\n",
    "        '''\n",
    "        使用最小二乘法\n",
    "        '''\n",
    "        b = x.shape[0]\n",
    "\n",
    "        if self.bias and x.shape[1] == self.c_in:\n",
    "            x = np.concatenate([x, np.ones((b, 1))], axis=1)\n",
    "\n",
    "        # === 请补全权重更新机制 ===\n",
    "        # self.weight = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文件中加载数据,并使用最小二乘法拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LeastSquareRegressor(c_in, c_out, 0, 0.1, True)\n",
    "model.fit_least_square(x_train, y_train)\n",
    "\n",
    "if model.bias:\n",
    "    print(\"weight: \", model.weight[:-1, :])\n",
    "    print(\"bias: \", model.weight[-1, :])\n",
    "else:\n",
    "    print(\"weight: \", model.weight)\n",
    "print(model.mse_loss(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制测试集数据和拟合到的模型预测结果."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def display_linear_regression(x_test, y_test, regressor):\n",
    "    plt.figure()\n",
    "\n",
    "    xx = np.linspace(np.min(x_test), np.max(x_test), 1000)\n",
    "    yy = regressor.predict(xx[:, np.newaxis])\n",
    "\n",
    "    plt.scatter(x_test, y_test)\n",
    "    plt.plot(xx, yy, c='red')\n",
    "    plt.show()\n",
    "\n",
    "display_linear_regression(x_test, y_test, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法\n",
    "\n",
    "请补全代码,完成梯度下降法拟合的线性模型.\n",
    "\n",
    "计算梯度为$grad = x^T(\\hat y - y)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GradientDescentRegressor(LinearRegressor):\n",
    "    \"\"\"\n",
    "    使用梯度下降法拟合线性模型\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        c_in: int, c_out: int,\n",
    "        init_mean: float, init_var: float,\n",
    "        bias: bool = True\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__(c_in, c_out, init_mean, init_var, bias)\n",
    "\n",
    "    def fit_gradient_descent(self,\n",
    "        x: np.ndarray, y: np.ndarray,\n",
    "        step: float=0.001,\n",
    "        iteration: int=100\n",
    "    )->None:\n",
    "        '''\n",
    "        使用梯度下降法拟合\n",
    "        '''\n",
    "        b = x.shape[0]\n",
    "\n",
    "        if self.bias and x.shape[1] == self.c_in:\n",
    "            x = np.concatenate([x, np.ones((b, 1))], axis=1)\n",
    "\n",
    "        # === 请补全梯度计算和梯度更新机制 ===\n",
    "        for idx in range(iteration):\n",
    "            # grad = ?\n",
    "\n",
    "            # self.weight = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GradientDescentRegressor(c_in, c_out, 0, 0.1, True)\n",
    "model.fit_gradient_descent(x_train, y_train, 0.01, 1000)\n",
    "\n",
    "if model.bias:\n",
    "    print(\"weight: \", model.weight[:-1, :])\n",
    "    print(\"bias: \", model.weight[-1, :])\n",
    "else:\n",
    "    print(\"weight: \", model.weight)\n",
    "print(model.mse_loss(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟退火法\n",
    "\n",
    "请补全代码,使用模拟退火法拟合线性模型.\n",
    "\n",
    "具体操作如下:\n",
    "1. 首先拟合线性模型.\n",
    "2. 为当前模型权重添加扰动.\n",
    "3. 重新拟合,比较新模型是否更优."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class SimulatedAnnealing(object):\n",
    "    def __init__(self, c_in, c_out, init_mean, init_var, bias) -> None:\n",
    "        # 定义线性模型\n",
    "        self.model = GradientDescentRegressor(c_in, c_out, init_mean, init_var, bias)\n",
    "\n",
    "    def fit(self,\n",
    "        x, y, step,\n",
    "        iterations: int = 100,\n",
    "        rounds:int = 10,\n",
    "        init_temp: float = 1.0\n",
    "    ):\n",
    "        # 首先使用给定的数据拟合线性模型\n",
    "        self.model.fit_gradient_descent(x, y, step, iterations)\n",
    "\n",
    "        # 初始化最优状态\n",
    "        best_model = deepcopy(self.model)\n",
    "        best_loss = self.model.mse_loss(x, y)\n",
    "        print(\"init_loss = \", best_loss)\n",
    "\n",
    "        temp = init_temp\n",
    "        # 开始多轮迭代\n",
    "        for round_idx in range(rounds):\n",
    "            # 温度下降\n",
    "            temp = temp * 0.9\n",
    "\n",
    "            # 添加扰动更新权重\n",
    "            cur_model = deepcopy(best_model)\n",
    "            # permute = ?\n",
    "            # cur_model.weight = ?\n",
    "\n",
    "            # 在新状态下拟合并计算新状态的损失\n",
    "            # cur_loss = ?\n",
    "\n",
    "            print(f\"#{round_idx}/{rounds}, temp = {temp:3f} best_loss = {best_loss:.4f} cur_loss = {cur_loss:.4f},\")\n",
    "\n",
    "            # 确认是否更新\n",
    "            if cur_loss < best_loss:\n",
    "                best_model = cur_model\n",
    "                best_loss = cur_loss\n",
    "\n",
    "\n",
    "model = SimulatedAnnealing(c_in, c_out, 0, 0.1, True)\n",
    "model.fit(x_train, y_train, 0.01, 10, 10)\n",
    "\n",
    "print(model.model.mse_loss(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
